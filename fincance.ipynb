{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0417b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrameWriter\n",
    "import psycopg2\n",
    "spark = SparkSession.builder.appName('finance')\\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config('spark.jars' , 'postgresql-42.7.3.jar'  )\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f515292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+--------+------+--------------+--------+---------------+\n",
      "| timestamp|   open|   high|     low| close|adjusted close|  volume|dividend amount|\n",
      "+----------+-------+-------+--------+------+--------------+--------+---------------+\n",
      "|2025-04-04| 242.74| 252.79|  226.88|227.48|        227.48|28005665|            0.0|\n",
      "|2025-03-28| 247.31| 254.32|  242.07| 244.0|         244.0|18354282|            0.0|\n",
      "|2025-03-21| 249.25| 254.63| 237.224|243.87|        243.87|27866866|            0.0|\n",
      "|2025-03-14| 261.56| 266.45|  241.68|248.35|        248.35|25513710|            0.0|\n",
      "|2025-03-07|254.735| 261.96|245.1823|261.54|        261.54|22284160|            0.0|\n",
      "|2025-02-28|  261.5|263.845|  246.54|252.44|        252.44|25541761|            0.0|\n",
      "|2025-02-21| 261.93| 265.09|  259.83|261.48|        261.48|18534169|            0.0|\n",
      "|2025-02-14| 250.86| 261.94|  246.87|261.28|        261.28|19898073|           1.67|\n",
      "|2025-02-07|  252.4| 265.72|  251.84|252.34|      250.6607|30149848|            0.0|\n",
      "|2025-01-31| 222.19|  261.8|  219.84| 255.7|      253.9983|39048997|            0.0|\n",
      "|2025-01-24| 224.99| 227.45|  220.35| 224.8|       223.304|15594637|            0.0|\n",
      "|2025-01-17| 217.89|225.955|  214.61|224.79|       223.294|18990367|            0.0|\n",
      "|2025-01-10|  223.0|226.711|   216.8|219.75|      218.2876|12337094|            0.0|\n",
      "|2025-01-03| 220.54| 223.66|   217.6|222.65|      221.1683|10819153|            0.0|\n",
      "|2024-12-27| 222.81|  225.4|  221.08|222.78|      221.2974| 9272351|            0.0|\n",
      "|2024-12-20| 230.73| 231.03|  220.03|223.36|      221.8735|28267440|            0.0|\n",
      "|2024-12-13|  238.0| 239.35|   227.8|230.82|      229.2839|20886084|            0.0|\n",
      "|2024-12-06|  227.5| 238.38|  225.51|238.04|      236.4558|18743737|            0.0|\n",
      "|2024-11-29| 223.35| 230.36|  222.65|227.41|      225.8966|17274177|            0.0|\n",
      "|2024-11-22|  207.0|  227.2|205.3701|222.97|      221.4861|21386866|            0.0|\n",
      "+----------+-------+-------+--------+------+--------------+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(r'weekly_adjusted_IBM.csv',header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a9f40f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp  NULLS =  0\n",
      "open  NULLS =  0\n",
      "high  NULLS =  0\n",
      "low  NULLS =  0\n",
      "close  NULLS =  0\n",
      "adjusted close  NULLS =  0\n",
      "volume  NULLS =  0\n",
      "dividend amount  NULLS =  0\n"
     ]
    }
   ],
   "source": [
    "#check null values\n",
    "for i in df.columns:\n",
    "    null = df.filter(df[i].isNull()).count()\n",
    "    print(i,' NULLS = ',null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "961a358f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: date (nullable = true)\n",
      " |-- open: double (nullable = true)\n",
      " |-- high: double (nullable = true)\n",
      " |-- low: double (nullable = true)\n",
      " |-- close: double (nullable = true)\n",
      " |-- adjusted close: double (nullable = true)\n",
      " |-- volume: integer (nullable = true)\n",
      " |-- dividend amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df03e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "#sort the entire dataframe by date\n",
    "df = df.orderBy(col(\"timestamp\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f841bda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+-------+------+--------------+--------+---------------+\n",
      "|      date|  open|  high|    low| close|adjusted close|  volume|dividend amount|\n",
      "+----------+------+------+-------+------+--------------+--------+---------------+\n",
      "|2025-04-04|242.74|252.79| 226.88|227.48|        227.48|28005665|            0.0|\n",
      "|2025-03-28|247.31|254.32| 242.07| 244.0|         244.0|18354282|            0.0|\n",
      "|2025-03-21|249.25|254.63|237.224|243.87|        243.87|27866866|            0.0|\n",
      "+----------+------+------+-------+------+--------------+--------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumnRenamed('timestamp','date')\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9b6ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed('adjusted close','adjusted_close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a461a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database vantage connected successfully\n"
     ]
    }
   ],
   "source": [
    "# Define database connection parameters including the database name\n",
    "db_params = {\n",
    "    'username':'postgres',\n",
    "    'password':'ahly9667',\n",
    "    'host':'localhost',\n",
    "    'port':'5432',\n",
    "    'database':'vantage'\n",
    "}\n",
    "\n",
    "# Connect to the new created database alayta_bank\n",
    "def db_connected():\n",
    "    connection = psycopg2.connect(user = 'postgres', \n",
    "                                  host= 'localhost',\n",
    "                                  password = 'ahly9667',\n",
    "                                  port = 5432,\n",
    "                                  database ='vantage')\n",
    "\n",
    "    return connection\n",
    "\n",
    "conn = db_connected()\n",
    "print(f\"Database {db_params['database']} connected successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb233632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables created successfully\n"
     ]
    }
   ],
   "source": [
    "#create a function to create related tables of schema\n",
    "def create_table():\n",
    "    conn = db_connected()\n",
    "    cursor= conn.cursor()\n",
    "    query = \"\"\"\n",
    "                 drop table if exists stock;\n",
    "\n",
    "                 create table stock(\n",
    "                 date date,\n",
    "                 open float,\n",
    "                 high float,\n",
    "                 low float,\n",
    "                 close float,\n",
    "                 adjusted_close float,\n",
    "                 volumn bigint,\n",
    "                 dividend_amount float)\n",
    "                 \n",
    "                \"\"\"\n",
    "    cursor.execute(query)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "create_table()\n",
    "print('Tables created successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fc7b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data into tables\n",
    "my_url = \"jdbc:postgresql://localhost:5432/vantage\"\n",
    "my_properties = {'user' : 'postgres',\n",
    "              'password' : 'ahly9667',\n",
    "              'driver' : 'org.postgresql.Driver'}\n",
    "\n",
    "df.write.jdbc( url= my_url , table = 'stock' , mode ='append' ,properties= my_properties)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
